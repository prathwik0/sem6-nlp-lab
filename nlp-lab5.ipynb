{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Representation for the given Corpus\n",
    "\n",
    "Generate n-gram representation for the given corpus and perform following operations on the corpus:\n",
    "    \n",
    "1. Preprocess the corpus for n-gram representation\n",
    "2. Display all tokens , distinct tokens and frequency of tokens in the corpus\n",
    "3. Bi-gram and frequency representation using user defined functions\n",
    "4. Tri-gram and frequency representation using user defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Arabian knights.These are the fairy tales of the east.The stories of the Arabian knights are translated in many languages\n"
     ]
    }
   ],
   "source": [
    "with open(\"./datasets/lab5_ngram.txt\") as f:\n",
    "    corpus = f.readline()\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data corpus = \n",
      " eos the arabian knights eos these are the fairy tales of the east eos the stories of the arabian knights are translated in many languages\n"
     ]
    }
   ],
   "source": [
    "corpus = corpus.lower()\n",
    "corpus = \"eos \" + corpus\n",
    "corpus = corpus.replace(\".\", \" eos \")\n",
    "\n",
    "# eos = end of string\n",
    "print(\"Preprocessed Data corpus = \\n\", corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find out Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of each tokens =  {'eos': 3, 'the': 5, 'arabian': 2, 'knights': 2, 'these': 1, 'are': 2, 'fairy': 1, 'tales': 1, 'of': 2, 'east': 1, 'stories': 1, 'translated': 1, 'in': 1, 'many': 1, 'languages': 1}\n"
     ]
    }
   ],
   "source": [
    "dct = {}\n",
    "for i in token:\n",
    "    dct[i] = 0  # make tokens as key\n",
    "for i in token:\n",
    "    dct[i] += 1  # count the frequency of each token\n",
    "print(\"Frequency of each tokens = \", dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate n-grams (bi-grams/ tri-grams) and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(k):\n",
    "    # ngram generation n = k\n",
    "    l = []\n",
    "    for i in range(len(token)):\n",
    "        l.append(token[i : i + k])  # creates sublist based on the n-gram\n",
    "    l = l[\n",
    "        :-1\n",
    "    ]  # remove last 1 remaining item from the list l which is incomplete with k\n",
    "\n",
    "    # ngram frequency\n",
    "    dct = {}\n",
    "    l = [\" \".join(i) for i in l]\n",
    "    for i in l:\n",
    "        dct[i] = 0\n",
    "    for i in l:\n",
    "        dct[i] += 1\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eos the': 2, 'the arabian': 2, 'arabian knights': 2, 'knights eos': 1, 'eos these': 1, 'these are': 1, 'are the': 1, 'the fairy': 1, 'fairy tales': 1, 'tales of': 1, 'of the': 2, 'the east': 1, 'east eos': 1, 'the stories': 1, 'stories of': 1, 'knights are': 1, 'are translated': 1, 'translated in': 1, 'in many': 1, 'many languages': 1}\n",
      "{'eos the arabian': 1, 'the arabian knights': 2, 'arabian knights eos': 1, 'knights eos these': 1, 'eos these are': 1, 'these are the': 1, 'are the fairy': 1, 'the fairy tales': 1, 'fairy tales of': 1, 'tales of the': 1, 'of the east': 1, 'the east eos': 1, 'east eos the': 1, 'eos the stories': 1, 'the stories of': 1, 'stories of the': 1, 'of the arabian': 1, 'arabian knights are': 1, 'knights are translated': 1, 'are translated in': 1, 'translated in many': 1, 'in many languages': 1, 'many languages': 1}\n"
     ]
    }
   ],
   "source": [
    "print(ngram(2))\n",
    "print(ngram(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prathwik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
