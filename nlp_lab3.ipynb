{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing Techniques on Email Spam Data\n",
    "\n",
    "1. Rename columns\n",
    "2. Expand contractions\n",
    "3. Lower case\n",
    "4. Remove punctuations\n",
    "5. Remove digits and word containing digits\n",
    "6. Remove stop words and specified words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./datasets/email.csv', usecols=[text, spam])\n",
    "\n",
    "print(data.head(10))\n",
    "print(data.info())\n",
    "\n",
    "data.rename(columns={'spam':'class'}, inplace=True)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"email.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rename columns\n",
    "\n",
    "column_mapping = { 'text': 'Email Content',\n",
    "                  'spam': 'Spam messages',\n",
    "                  # Add more columns as needed \n",
    "                 }\n",
    "\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Save the dataframe back to CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Expand contractions\n",
    "\n",
    "eg. don't -> do not, it's -> it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "text = df[\"Email content\"][0]\n",
    "print('Original Text:\\n', text)\n",
    "print('Expanded Text:\\n')\n",
    "for i in text.split():\n",
    "\t\tprint(contractions.fix(i), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['Email Content'].str.lower()\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove digits and word containing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: re.sub('\\w*\\d\\w*', '', x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remove stop words and specified words\n",
    "\n",
    "Stopwords are the most commonly occurring words which do not provide any valuable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "df['text'][3]\n",
    "\n",
    "stop_words = set(stopwords.word('english'))\n",
    "stop_words.add('subject')\n",
    "def remove_stopwords(text):\n",
    "\t\treturn \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: remove_stopwords(x))\n",
    "df['text'][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prathwik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
