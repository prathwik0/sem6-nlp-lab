{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider students.txt and perform the following operations:\n",
    "\n",
    "1. Tokenize the email ids from the given students.txt using Spacy\n",
    "2. Tokenize all email ids from the given students.txt using NLTK\n",
    "3. Collecting dataset websites from a book paragraph using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the email ids from the given students.txt using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# we are using engligh core web spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize all email ids from the given students.txt using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emails = re.findall(\"[a-zA-Z0-9]+@[a-zA-Z0-9]+\\.[a-z]+\", text)\n",
    "print(\"EMAIL ID:\\n\", emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting dataset websites from a book paragraph using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spanning strings over multiple lines -> ```\n",
    "text = ```\n",
    "Look for data to help you address the question. Governments are good sources because data from public resources...\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.nor.org/gss+website/, and the...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "url = []\n",
    "for t in doc:\n",
    "    if t.like_url:\n",
    "        url.append(t.text)\n",
    "print('URL:\\n', url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Extract all money transactions from given sentence along with currency using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Aron gave two $ to Shawn, Smith gave 500 â‚¬ to Johan\"\n",
    "\n",
    "doc = nlp(transactions)\n",
    "for token in doc:\n",
    "\n",
    "# The token.i attribute returns the index of the current token in the document,\n",
    "# so doc[token.i+1] accesses the next token in the document\n",
    "\tif token.like_num and doc[token.i+1].is_currency:\n",
    "\t\tprint(token, doc[token.i+1].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prathwik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
